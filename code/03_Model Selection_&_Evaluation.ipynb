{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebacf5cc-ed81-4783-8fbd-fe44088acf89",
   "metadata": {},
   "source": [
    "# **<span style=\"font-size:larger;\"> 03: <span style=\"color:blue\">Model Selection & Evaluation</span>** #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6c2735bb-5619-46c9-8da7-0044049f842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import f1_score, confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "stops = (set(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00dab6cc-5f22-4bf3-a219-e1729af7a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Data\n",
    "df = pd.read_csv('../data/full_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e402237-9264-4655-bf84-c8256364029f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b7d2a-6adc-4bb9-8829-2a7150f093ee",
   "metadata": {},
   "source": [
    "# **3.1 Model Setup**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c656894-634a-4265-97b8-180a7ddf5e15",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23b01b56-64cf-4917-bbe0-5318ea153ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.503726\n",
       "1    0.496274\n",
       "Name: is_AnimalsBeingJerks, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_AnimalsBeingJerks'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292ec94c-0b9d-4888-a640-0875ef8c6c8d",
   "metadata": {},
   "source": [
    "As is, if my model were to predict that every submission were from r/animalsbeingjerks, the model would be correct 50.3% of the time. Our goal is to improve this percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c294ce50-9a59-4dbc-b3f5-c5ce17fcb305",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a419cdf5-d941-4e80-a95c-97980278c6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['stemmed'] # Chose stemmed over lemmatized as it seemed to perform better\n",
    "y = df['is_AnimalsBeingJerks']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a39ccd-e019-40ea-84af-bbe3b6ab11e7",
   "metadata": {},
   "source": [
    "# **3.2 Pipeline and GridSearchCV**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685bf850-d5a5-499e-aba1-bf3efafa4f08",
   "metadata": {},
   "source": [
    "The `Pipeline` and `GridSearchCV` tools allow us to program multiple hyperparameters across our models. It will generate a model with each combination of our desired hyperparameters and optimize the highest-scoring result.\n",
    "\n",
    "We will run a single model for each of the following 8 classifiers:\n",
    "\n",
    "- Logistic Regression\n",
    "- Bernouli Naive Bayes\n",
    "- Multinomial Naive Bayes\n",
    "- Random Forest\n",
    "- Gradient Boost\n",
    "- AdaBoost\n",
    "- Support Vector Machine\n",
    "- K-Nearest Neighbors\n",
    "\n",
    "We will run two GridSearches to benchmark these models for two feature extraction techniques: `CountVectorizer` and `TfidfVectorizer`. We can use the accuracy of the results to narrow our model selection to the most effective approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a195213-dcb9-405f-9885-1c1157bc2d8a",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18324009-0dc2-4dda-85dc-9d66674afc12",
   "metadata": {},
   "source": [
    "**TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01b0b726-9316-4ae6-a409-f83a552ca6bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None}\n",
      "Best Estimator Score Train:  0.8403765690376569\n",
      "Best Estimator Score Test:  0.7213680577345466\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([    \n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression()),\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tfidf__stop_words' : [None, stops],\n",
    "    'tfidf__ngram_range' : [(1,1),(1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ', gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ba93d-7d78-4d35-aaf0-5dfc594ac709",
   "metadata": {},
   "source": [
    "**Count Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0099ef2c-8b95-4ae9-ac04-0e7a3e9dee1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'cv__ngram_range': (1, 2), 'cv__stop_words': None}\n",
      "Best Estimator Score Train:  0.9784518828451882\n",
      "Best Estimator Score Test:  0.7251333542516473\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([    \n",
    "    ('cv', CountVectorizer()),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cv__stop_words' : [None, stops],\n",
    "    'cv__ngram_range' : [(1,1),(1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5bb0df-7ec5-47d4-a425-46d84c3c20ec",
   "metadata": {},
   "source": [
    "## 2. Bernouli Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2f9452-87f7-48bf-af0c-ccc9b75e3abc",
   "metadata": {},
   "source": [
    "**TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d18e638-f72a-4353-a7f5-9f6976d61ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None}\n",
      "Best Estimator Score Train:  0.9401673640167364\n",
      "Best Estimator Score Test:  0.728898650768748\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('bnb', BernoulliNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tfidf__stop_words' : [None, stops],\n",
    "    'tfidf__ngram_range' : [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1265661d-9aaf-473b-9793-e5ec3d685a79",
   "metadata": {},
   "source": [
    "**Count Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28f68e31-6f7b-4011-a0d6-011e740253c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'cv__ngram_range': (1, 2), 'cv__stop_words': None}\n",
      "Best Estimator Score Train:  0.9401673640167364\n",
      "Best Estimator Score Test:  0.728898650768748\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('bnb', BernoulliNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cv__stop_words' : [None, stops],\n",
    "    'cv__ngram_range' : [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc180eea-8cac-4ed3-851d-8b66bb97fe67",
   "metadata": {},
   "source": [
    "## 3. Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a38d04-3ef7-4ab3-8ade-fdc17ec7b47d",
   "metadata": {},
   "source": [
    "**TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a5cd6c8c-6eac-4ea0-a289-85c29780fbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None}\n",
      "Best Estimator Score Train:  0.943723849372385\n",
      "Best Estimator Score Test:  0.73046752431754\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tfidf__stop_words' : [None, stops],\n",
    "    'tfidf__ngram_range' : [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1bade7-f08a-4f95-9f8d-3f6e40cd9d25",
   "metadata": {},
   "source": [
    "**Count Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ebd196d-767c-446f-b88e-3a5e65f6eb63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'cv__ngram_range': (1, 2), 'cv__stop_words': None}\n",
      "Best Estimator Score Train:  0.9439330543933054\n",
      "Best Estimator Score Test:  0.7329777219956072\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cv__stop_words' : [None, stops],\n",
    "    'cv__ngram_range' : [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246ca7fa-b5bf-41a9-9ed8-706d63c42159",
   "metadata": {},
   "source": [
    "## 4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd6b791-adf0-4f27-b512-1b8aee260e92",
   "metadata": {},
   "source": [
    "**TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a012b5d-41b2-45e4-9f5a-4b90a7bc62b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None}\n",
      "Best Estimator Score Train:  0.9960251046025105\n",
      "Best Estimator Score Test:  0.6975211797929087\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tfidf__stop_words' : [None, stops],\n",
    "    'tfidf__ngram_range' : [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf481466-1009-49f2-82aa-c3b28922c69d",
   "metadata": {},
   "source": [
    "**Count Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dee595b3-68a9-4fe0-ba96-1fd03e22b531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'cv__ngram_range': (1, 2), 'cv__stop_words': None}\n",
      "Best Estimator Score Train:  0.9960251046025105\n",
      "Best Estimator Score Test:  0.7037966739880765\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cv__stop_words' : [None, stops],\n",
    "    'cv__ngram_range' : [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce8fe22-224f-44df-8a55-8b640cf3b070",
   "metadata": {},
   "source": [
    "## 5. Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02b1b96-79b0-4e41-b613-9d857a5d354e",
   "metadata": {},
   "source": [
    "**TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "820582b8-b630-485b-aa35-0ed8e8ddfa83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': None}\n",
      "Best Estimator Score Train:  0.6928870292887029\n",
      "Best Estimator Score Test:  0.6564166928145592\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tfidf__stop_words' : [None, stops],\n",
    "    'tfidf__ngram_range' : [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f9be67-ec08-4330-bb11-a8d6ab0ecc6e",
   "metadata": {},
   "source": [
    "**Count Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c1ec794a-0b2a-4df6-a0c9-49a80e202f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'cv__ngram_range': (1, 2), 'cv__stop_words': None}\n",
      "Best Estimator Score Train:  0.6926778242677825\n",
      "Best Estimator Score Test:  0.657044242234076\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cv__stop_words' : [None, stops],\n",
    "    'cv__ngram_range' : [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1aa1c-f22c-4ce6-86c0-d80dc5272fc8",
   "metadata": {},
   "source": [
    "## 6. Ada Boost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c999b5-9873-4c3b-906e-b790bcb3b5be",
   "metadata": {},
   "source": [
    "**TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0c00e752-26dc-4cae-b0b3-cc10a24bd9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'tfidf__ngram_range': (1, 2), 'tfidf__stop_words': {'few', 'am', 'all', 'ain', 'd', 'themselves', 'who', 'been', 'have', 'did', 'against', 'below', 'himself', 'for', 'i', 'theirs', 'after', \"don't\", \"you'd\", 'no', 'an', 'wouldn', 'was', 'and', 'under', \"shan't\", \"needn't\", 'ours', 'which', 'don', 'then', 'those', 'my', 'are', \"you're\", 'were', 'whom', 'during', 'itself', 'between', 'is', \"couldn't\", 'why', 't', 'these', \"weren't\", \"should've\", 'now', \"haven't\", \"shouldn't\", \"hadn't\", 'or', \"you'll\", 'the', 'most', 'wasn', 'our', 'them', 'this', 'here', 'couldn', \"it's\", 'because', \"mustn't\", \"didn't\", \"mightn't\", 'her', 'had', \"won't\", 've', 'they', 'it', 'other', 'hadn', 'ourselves', 'at', 'where', 'needn', 'yourself', 'myself', 'by', 'do', 'but', 'yours', 'until', 'than', 'its', 're', 'having', 'same', 'isn', 'while', \"that'll\", 'doing', 'shouldn', 'hers', 'in', 'll', 'of', 'there', \"aren't\", 'not', 'out', 'what', 'being', 'some', 'through', 'down', 'aren', 'so', 'how', 'y', 'too', 'does', 'a', 'above', 'herself', 'you', 'your', \"wasn't\", 'yourselves', 'we', 'she', 'should', 'nor', 'weren', 'up', 'mightn', 'when', 'has', 'any', 'only', \"you've\", 'such', 'further', 'didn', 'him', 'his', 'off', 'haven', 'me', 'he', 'doesn', \"she's\", 'own', 'very', 'each', 'as', \"hasn't\", 'just', 'm', 'again', 'on', 'won', 'about', 'over', 'will', 'be', 'shan', 'that', 'o', 'once', 'hasn', 'mustn', 'more', \"doesn't\", 'both', 'from', 'their', 'with', \"wouldn't\", 'into', 's', \"isn't\", 'before', 'to', 'ma', 'if', 'can'}}\n",
      "Best Estimator Score Train:  0.6580543933054394\n",
      "Best Estimator Score Test:  0.6413555067461563\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('ab', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tfidf__stop_words' : [None, stops],\n",
    "    'tfidf__ngram_range' : [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c57f56-503c-4b43-a17b-8d36e2386fca",
   "metadata": {},
   "source": [
    "**Count Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "17714a53-7bb3-463e-aa5f-bbcec5fac54f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'cv__ngram_range': (1, 2), 'cv__stop_words': None}\n",
      "Best Estimator Score Train:  0.6596234309623431\n",
      "Best Estimator Score Test:  0.6523376215877\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('ab', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cv__stop_words' : [None, stops],\n",
    "    'cv__ngram_range' : [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbce8c8a-c57d-454d-a0e9-f90b2b5239a1",
   "metadata": {},
   "source": [
    "## 7. Support Vector Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed025fd4-4596-40ab-ad28-3bc05c5f9f01",
   "metadata": {},
   "source": [
    "**TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12551904-8644-47ab-8369-844e872b902b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': None}\n",
      "Best Estimator Score Train:  0.9547071129707113\n",
      "Best Estimator Score Test:  0.7317226231565735\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('svc', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tfidf__stop_words' : [None, stops],\n",
    "    'tfidf__ngram_range' : [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64811cd3-b1a4-43d8-aed3-64a6cea0c847",
   "metadata": {},
   "source": [
    "**Count Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33a3a7f6-1bef-4827-a6cb-f2b96edff8b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': None}\n",
      "Best Estimator Score Train:  0.9150627615062762\n",
      "Best Estimator Score Test:  0.714465014119862\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('svc', SVC(random_state=42))\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cv__stop_words' : [None, stops],\n",
    "    'cv__ngram_range' : [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056f9046-544e-4a2f-9eb2-269b676b7c96",
   "metadata": {},
   "source": [
    "## 8. KNeighbors Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2811a8f1-4935-4b57-95d0-bbaae9e3a833",
   "metadata": {},
   "source": [
    "**TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "639ee71a-2223-4a54-bc5d-a1a5674de3a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'tfidf__ngram_range': (1, 1), 'tfidf__stop_words': {'few', 'am', 'all', 'ain', 'd', 'themselves', 'who', 'been', 'have', 'did', 'against', 'below', 'himself', 'for', 'i', 'theirs', 'after', \"don't\", \"you'd\", 'no', 'an', 'wouldn', 'was', 'and', 'under', \"shan't\", \"needn't\", 'ours', 'which', 'don', 'then', 'those', 'my', 'are', \"you're\", 'were', 'whom', 'during', 'itself', 'between', 'is', \"couldn't\", 'why', 't', 'these', \"weren't\", \"should've\", 'now', \"haven't\", \"shouldn't\", \"hadn't\", 'or', \"you'll\", 'the', 'most', 'wasn', 'our', 'them', 'this', 'here', 'couldn', \"it's\", 'because', \"mustn't\", \"didn't\", \"mightn't\", 'her', 'had', \"won't\", 've', 'they', 'it', 'other', 'hadn', 'ourselves', 'at', 'where', 'needn', 'yourself', 'myself', 'by', 'do', 'but', 'yours', 'until', 'than', 'its', 're', 'having', 'same', 'isn', 'while', \"that'll\", 'doing', 'shouldn', 'hers', 'in', 'll', 'of', 'there', \"aren't\", 'not', 'out', 'what', 'being', 'some', 'through', 'down', 'aren', 'so', 'how', 'y', 'too', 'does', 'a', 'above', 'herself', 'you', 'your', \"wasn't\", 'yourselves', 'we', 'she', 'should', 'nor', 'weren', 'up', 'mightn', 'when', 'has', 'any', 'only', \"you've\", 'such', 'further', 'didn', 'him', 'his', 'off', 'haven', 'me', 'he', 'doesn', \"she's\", 'own', 'very', 'each', 'as', \"hasn't\", 'just', 'm', 'again', 'on', 'won', 'about', 'over', 'will', 'be', 'shan', 'that', 'o', 'once', 'hasn', 'mustn', 'more', \"doesn't\", 'both', 'from', 'their', 'with', \"wouldn't\", 'into', 's', \"isn't\", 'before', 'to', 'ma', 'if', 'can'}}\n",
      "Best Estimator Score Train:  0.7382845188284519\n",
      "Best Estimator Score Test:  0.587700031377471\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'tfidf__stop_words' : [None, stops],\n",
    "    'tfidf__ngram_range' : [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca3aec4-7a11-4324-9d9a-134f1595a08a",
   "metadata": {},
   "source": [
    "**Count Vectorizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "69a0f8c0-9cda-403d-8d59-cd1814e830c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "Best Params:  {'cv__ngram_range': (1, 1), 'cv__stop_words': None}\n",
      "Best Estimator Score Train:  0.7631799163179916\n",
      "Best Estimator Score Test:  0.6225290241606527\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cv__stop_words' : [None, stops],\n",
    "    'cv__ngram_range' : [(1,1), (1,2)],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e812f19-ca5c-4057-817e-1f3709616b69",
   "metadata": {},
   "source": [
    "Overall, Multinomial Naive Bayes (CountVectorized) proved to be the most efficient model. We will continue to tune the parameters to optimize this model as much as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdcd3c3-cf03-439c-bc02-bb75b90973ee",
   "metadata": {},
   "source": [
    "# **3.3 Model Selection & Optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0135bc4-6d66-45fe-8e9a-0291994c1b5c",
   "metadata": {},
   "source": [
    "Looking at model types, we can see that the Count Vectorized Multinomial Naive Bayes models performed best on an initial run.\n",
    "\n",
    "### **Multinomial Naive Bayes (CVEC)**\n",
    "\n",
    "**Best Parameters:**\n",
    "- cv__ngram_range: (1, 2)\n",
    "- cv__stop_words: None\n",
    "\n",
    "**Scores:**\n",
    "- Training Score:  0.9439330543933054\n",
    "- Testing Score:  0.7329777219956072\n",
    "\n",
    "\n",
    "Our goal while fine tuning our model is to improve these scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff9ac6a-274b-4252-8746-1fe7121f8bd3",
   "metadata": {},
   "source": [
    "### Optimizing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "beeb3dd4-99ee-4681-87a5-adae12711bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "Best Params:  {'cv__min_df': 1, 'cv__ngram_range': (1, 2), 'cv__stop_words': None, 'mnb__alpha': 1}\n",
      "Best Estimator Score Train:  0.9439330543933054\n",
      "Best Estimator Score Test:  0.7329777219956072\n"
     ]
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'cv__min_df': [1, 2],\n",
    "    'cv__stop_words' : [None, stops],\n",
    "    'cv__ngram_range' : [(1,1),(1,2), (1,3)],\n",
    "    'mnb__alpha' : [0.1, 1, 10,100],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(pipe, params, cv=5, verbose=2, n_jobs=-1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print('Best Params: ',gs.best_params_)\n",
    "print('Best Estimator Score Train: ', gs.best_estimator_.score(X_train, y_train))\n",
    "print('Best Estimator Score Test: ', gs.best_estimator_.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5487448-f3f2-457f-8057-c339ddb40af4",
   "metadata": {},
   "source": [
    "Unfortunately, even with extra parameters, we are unable to improve our model. It is important to note that the addition of custom stop words did not improve our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27a346c-47b0-4f96-8090-827a400f2526",
   "metadata": {},
   "source": [
    "# **3.4 Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c809e1f6-7bb3-4386-a6fe-0cf5d7740c12",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b474bcfd-6f39-4891-ae97-5f0c10f1126e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create predictions variable\n",
    "preds = gs.predict(X_test)\n",
    "\n",
    "# Create confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "#Create confusion matrix visual\n",
    "labels = ['r/HumansBeingBros', 'r/AnimalsBeingJerks']\n",
    "plot_confusion_matrix(gs, X_test, y_test, cmap='Blues');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35e69d4-0ee1-459b-992f-a904beef9223",
   "metadata": {},
   "source": [
    "This confusion matrix shows that the model incorrectly predicted r/AnimalsBeingJerks (1) when it was actually r/AnimalsBeingBros (0) 458 times. Also, the model incorrectly predicted r/AnimalsBeingBros (0) when it was actually r/AnimalsBeingJerks (1) 393 times. \n",
    "\n",
    "More specifically, this is how our model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77400650-3059-4b03-9087-422a16e0ac9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7329777219956072\n",
      "Misclassification Rate:  0.2670222780043928\n",
      "Sensitivity:  0.7515802781289507\n",
      "Specificity:  0.7146417445482866\n",
      "Precision:  0.7219186399514268\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", (tn + tp) / (tn + fp + fn + tp))\n",
    "print('Misclassification Rate: ', (fp+fn)/(tp+fp+tn+fn))\n",
    "print(\"Sensitivity: \", tp / (tp + fn))\n",
    "print(\"Specificity: \", tn / (tn + fp))\n",
    "print(\"Precision: \", tp / (tp + fp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4033e4b5-768f-4cc8-910b-58b82e3f1d79",
   "metadata": {},
   "source": [
    "## Probability Data Frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcc0dbb-ce59-4cd6-8947-b5916a74a8cd",
   "metadata": {},
   "source": [
    "A Data Frame will be created to display the probabilities of titles being in each subreddit. Further investigation will be done to determine why the model misclassified certain titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a9ea864-b904-42b5-8047-718b47d28e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pd.DataFrame({\n",
    "    'title' : X_test, \n",
    "    'actual' : y_test, \n",
    "    'predicted' : gs.predict(X_test),\n",
    "    'P(r/AnimalsBeingBros)' : [i[0] for i in gs.predict_proba(X_test)],\n",
    "    'P(r/AnimalsBeingJerks)' : [i[1] for i in gs.predict_proba(X_test)]})\n",
    "preds['Prob Diff'] = np.abs(preds['P(r/AnimalsBeingBros)'] - preds['P(r/AnimalsBeingJerks)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c412af-82fc-4f64-aad2-e9becf47873f",
   "metadata": {},
   "source": [
    "### Top 5 Titles with the Highest Probability of Being in r/AnimalsBeingBros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7f3a5e80-2ea3-46e3-9c3a-ffbe7906fb4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>P(r/AnimalsBeingBros)</th>\n",
       "      <th>P(r/AnimalsBeingJerks)</th>\n",
       "      <th>Prob Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>các con vật tiếng việt them học nói tên các loài động vật biển dại trẻ thông minh sớm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.368885e-48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>dại bé học nói các con vật tiếng việt them tập nhận biết tiếng kêyou động vật dại trẻ thông minh sớm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.671777e-55</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>them học con vật bé tập nói tên các loài động vật sống dưới biển tiếng v ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.718824e-32</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>động vật hoang dã dại bé học đọc con vật bằng tiếng anh dại trẻ thông minh sớm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.886881e-38</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1762</th>\n",
       "      <td>con vật và tiếng kêyou them tập nói tên động vật tiếng việt và học tiếng kêyou dại trẻ thông minh sớm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.202637e-57</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      title  \\\n",
       "1863                  các con vật tiếng việt them học nói tên các loài động vật biển dại trẻ thông minh sớm   \n",
       "1581   dại bé học nói các con vật tiếng việt them tập nhận biết tiếng kêyou động vật dại trẻ thông minh sớm   \n",
       "2081                           them học con vật bé tập nói tên các loài động vật sống dưới biển tiếng v ...   \n",
       "1529                         động vật hoang dã dại bé học đọc con vật bằng tiếng anh dại trẻ thông minh sớm   \n",
       "1762  con vật và tiếng kêyou them tập nói tên động vật tiếng việt và học tiếng kêyou dại trẻ thông minh sớm   \n",
       "\n",
       "      actual  predicted  P(r/AnimalsBeingBros)  P(r/AnimalsBeingJerks)  \\\n",
       "1863       0          0                    1.0            8.368885e-48   \n",
       "1581       0          0                    1.0            6.671777e-55   \n",
       "2081       0          0                    1.0            2.718824e-32   \n",
       "1529       0          0                    1.0            2.886881e-38   \n",
       "1762       0          0                    1.0            3.202637e-57   \n",
       "\n",
       "      Prob Diff  \n",
       "1863        1.0  \n",
       "1581        1.0  \n",
       "2081        1.0  \n",
       "1529        1.0  \n",
       "1762        1.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "preds.sort_values(by='P(r/AnimalsBeingBros)', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14399eb1-2363-457e-ae81-43821ba1b694",
   "metadata": {},
   "source": [
    "Well, this is certainly interesting. Google translate informs me that in Vietnamese, the first title roughly says, \"Vietnamese animals learn to say the names of wild sea animals, young and intelligent, early.\" Perhaps there is a Vietnamese active user  on r/AnimalsBeingBros and our model was able to accurately predict which subreddit these titles belong in based on their language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc882dc-245f-4c71-aee3-305c040d4819",
   "metadata": {},
   "source": [
    "### Top 5 Titles with the Highest Probability of Being in r/AnimalsBeingJerks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99a7122a-faa3-481a-a9aa-d7a9b95d4e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>P(r/AnimalsBeingBros)</th>\n",
       "      <th>P(r/AnimalsBeingJerks)</th>\n",
       "      <th>Prob Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12306</th>\n",
       "      <td>gari thought it would be funni to have a poo in the kitchen right in front of us a few day befor she pass away ... safe to say she could not have care less 😂</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.092695e-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12274</th>\n",
       "      <td>she want pictur of the alpaca he wa be an unwiped-asshol to her all morn i just want to send my friend a christma video thi wa the christma gift i did not know i want</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.279176e-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8038</th>\n",
       "      <td>our belov pet wild magpi ha recent start smash it is head off our window whi it is 5am and ha been at it for 18 hour give or take a few tea break</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.264108e-11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11622</th>\n",
       "      <td>one of the cat threw up on my charg cord it dri and i did not notic when i put it into my phone to charg befor pass out now my phone charg port is rusti dude i have had thi phone for 4 month my phone is pivot in my art work</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.624650e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>slap slap slap slap slap ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5.329238e-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                 title  \\\n",
       "12306                                                                    gari thought it would be funni to have a poo in the kitchen right in front of us a few day befor she pass away ... safe to say she could not have care less 😂   \n",
       "12274                                                           she want pictur of the alpaca he wa be an unwiped-asshol to her all morn i just want to send my friend a christma video thi wa the christma gift i did not know i want   \n",
       "8038                                                                                 our belov pet wild magpi ha recent start smash it is head off our window whi it is 5am and ha been at it for 18 hour give or take a few tea break   \n",
       "11622  one of the cat threw up on my charg cord it dri and i did not notic when i put it into my phone to charg befor pass out now my phone charg port is rusti dude i have had thi phone for 4 month my phone is pivot in my art work   \n",
       "6574                                                                                                                                                                                                      slap slap slap slap slap ...   \n",
       "\n",
       "       actual  predicted  P(r/AnimalsBeingBros)  P(r/AnimalsBeingJerks)  \\\n",
       "12306       1          1           1.092695e-11                     1.0   \n",
       "12274       1          1           3.279176e-11                     1.0   \n",
       "8038        1          1           5.264108e-11                     1.0   \n",
       "11622       1          1           1.624650e-10                     1.0   \n",
       "6574        1          1           5.329238e-10                     1.0   \n",
       "\n",
       "       Prob Diff  \n",
       "12306        1.0  \n",
       "12274        1.0  \n",
       "8038         1.0  \n",
       "11622        1.0  \n",
       "6574         1.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "preds.sort_values(by='P(r/AnimalsBeingJerks)', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fd67dd-6c0c-4794-abca-6b33b1271992",
   "metadata": {},
   "source": [
    "There are no surprises here. \"One of the cats threw up on my charging cord. It dried and I didn't notice when I put it into my phone to charge before passing out. Now my phones charging port is rusty. Dude ive had this phone for 4 months, my phone is pivotal in my art work,” is a personal favorite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1376c84-b40e-4afa-af3d-7a61aa90ac7d",
   "metadata": {},
   "source": [
    "### Top 10 Misclassified Titles with a High Probability Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b72682b-4dbd-418f-a4da-a5d8d1b3a416",
   "metadata": {},
   "source": [
    "These are titles the model misclassified with high confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b756e0e1-a39a-43bc-b01e-dd07c28f0933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>P(r/AnimalsBeingBros)</th>\n",
       "      <th>P(r/AnimalsBeingJerks)</th>\n",
       "      <th>Prob Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>i did not join in anticip that internet date would work and then unexpectedli found the perfect partner and am veri veri happi mmnonqcjn</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.519490e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475</th>\n",
       "      <td>do not realli know where to post thi but i need help thi is my mom dog- rescu she enter him into thi contest and doe not want to ask anyon to vote so she will not be disappoint when they do not ☹️ if you could just click the vote button it would make my mom day</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.076523e-08</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>do not let thi get your goat ... but can not we all just get along</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.749415e-05</td>\n",
       "      <td>0.999973</td>\n",
       "      <td>0.999945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2691</th>\n",
       "      <td>funni goat d hilari goat make strang nois as he tri to get food</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.872287e-05</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.999923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4573</th>\n",
       "      <td>he hurt hi back left paw so i gave him a pain killer and he pass out on me she came and cuddl close but not too close just keep her paw on top of hi so she know hi everi move</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.090207e-05</td>\n",
       "      <td>0.999939</td>\n",
       "      <td>0.999878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4080</th>\n",
       "      <td>my cat sit on nthe stair when it rain and he been do thi for the last few day and i feel bad for him</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9.934490e-05</td>\n",
       "      <td>0.999901</td>\n",
       "      <td>0.999801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2694</th>\n",
       "      <td>cat decid she wa not move ...... and i wa late for work😂</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.128772e-04</td>\n",
       "      <td>0.999887</td>\n",
       "      <td>0.999774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4278</th>\n",
       "      <td>i got lost backpack in malaysia and found thi woofer she wa super wari at first but open right up after some pat then she walk with me for about 5 mile until i found my way back to my hostel</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.300542e-04</td>\n",
       "      <td>0.999870</td>\n",
       "      <td>0.999740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4584</th>\n",
       "      <td>my dogo is alway look at my garden through the window even if it is alway the same thing i start to look with my dog and i got so relax that now i do it everi day</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.399412e-04</td>\n",
       "      <td>0.999860</td>\n",
       "      <td>0.999720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10246</th>\n",
       "      <td>my best friend forev</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.998534e-01</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.999707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                       title  \\\n",
       "232                                                                                                                                 i did not join in anticip that internet date would work and then unexpectedli found the perfect partner and am veri veri happi mmnonqcjn   \n",
       "3475   do not realli know where to post thi but i need help thi is my mom dog- rescu she enter him into thi contest and doe not want to ask anyon to vote so she will not be disappoint when they do not ☹️ if you could just click the vote button it would make my mom day   \n",
       "2162                                                                                                                                                                                                      do not let thi get your goat ... but can not we all just get along   \n",
       "2691                                                                                                                                                                                                         funni goat d hilari goat make strang nois as he tri to get food   \n",
       "4573                                                                                          he hurt hi back left paw so i gave him a pain killer and he pass out on me she came and cuddl close but not too close just keep her paw on top of hi so she know hi everi move   \n",
       "4080                                                                                                                                                                    my cat sit on nthe stair when it rain and he been do thi for the last few day and i feel bad for him   \n",
       "2694                                                                                                                                                                                                                cat decid she wa not move ...... and i wa late for work😂   \n",
       "4278                                                                          i got lost backpack in malaysia and found thi woofer she wa super wari at first but open right up after some pat then she walk with me for about 5 mile until i found my way back to my hostel   \n",
       "4584                                                                                                      my dogo is alway look at my garden through the window even if it is alway the same thing i start to look with my dog and i got so relax that now i do it everi day   \n",
       "10246                                                                                                                                                                                                                                                   my best friend forev   \n",
       "\n",
       "       actual  predicted  P(r/AnimalsBeingBros)  P(r/AnimalsBeingJerks)  \\\n",
       "232         0          1           4.519490e-08                1.000000   \n",
       "3475        0          1           6.076523e-08                1.000000   \n",
       "2162        0          1           2.749415e-05                0.999973   \n",
       "2691        0          1           3.872287e-05                0.999961   \n",
       "4573        0          1           6.090207e-05                0.999939   \n",
       "4080        0          1           9.934490e-05                0.999901   \n",
       "2694        0          1           1.128772e-04                0.999887   \n",
       "4278        0          1           1.300542e-04                0.999870   \n",
       "4584        0          1           1.399412e-04                0.999860   \n",
       "10246       1          0           9.998534e-01                0.000147   \n",
       "\n",
       "       Prob Diff  \n",
       "232     1.000000  \n",
       "3475    1.000000  \n",
       "2162    0.999945  \n",
       "2691    0.999923  \n",
       "4573    0.999878  \n",
       "4080    0.999801  \n",
       "2694    0.999774  \n",
       "4278    0.999740  \n",
       "4584    0.999720  \n",
       "10246   0.999707  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "diff = preds.loc[preds['actual'] != preds['predicted']]\n",
    "diff.sort_values(by='Prob Diff', ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74d0208-a60e-44ad-a108-a42c378f7c9a",
   "metadata": {},
   "source": [
    "Some of these titles would be difficult even for a human to correctly classify. Titles like \"My best friend forever,\" would intuitively belong in r/AnimalsBeingBros, however this belonged in r/AnimalsBeingJerks. Unfortunatey, there is not a lot that my model can do to better predict those misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9216aa-324c-43da-9724-7137b760e79c",
   "metadata": {},
   "source": [
    "### Top 10 Misclassified Titles with a Low Probability Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce9426-8e77-431a-afc6-81ddfd0ebcc2",
   "metadata": {},
   "source": [
    "These are titles the model misclassified with low confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8086167b-4fd4-4528-a7cc-59df6655bd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "      <th>P(r/AnimalsBeingBros)</th>\n",
       "      <th>P(r/AnimalsBeingJerks)</th>\n",
       "      <th>Prob Diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10586</th>\n",
       "      <td>tırtıl</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503766</td>\n",
       "      <td>0.496234</td>\n",
       "      <td>0.007531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12028</th>\n",
       "      <td>angeri</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503766</td>\n",
       "      <td>0.496234</td>\n",
       "      <td>0.007531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11895</th>\n",
       "      <td>choooommmmppppppppppppppppp</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503766</td>\n",
       "      <td>0.496234</td>\n",
       "      <td>0.007531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10162</th>\n",
       "      <td>lipstick</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503766</td>\n",
       "      <td>0.496234</td>\n",
       "      <td>0.007531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11508</th>\n",
       "      <td>heheheheh 🤣🤣🤣🤣🤣🤣</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503766</td>\n",
       "      <td>0.496234</td>\n",
       "      <td>0.007531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10623</th>\n",
       "      <td>aboos</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503766</td>\n",
       "      <td>0.496234</td>\n",
       "      <td>0.007531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10494</th>\n",
       "      <td>i log onto a famili photo album and thi wa the first photo upload ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503743</td>\n",
       "      <td>0.496257</td>\n",
       "      <td>0.007486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10851</th>\n",
       "      <td>duck v. cat</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.503720</td>\n",
       "      <td>0.496280</td>\n",
       "      <td>0.007440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5882</th>\n",
       "      <td>🔥 a smile black crest macaqu by mogen troll</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.496861</td>\n",
       "      <td>0.503139</td>\n",
       "      <td>0.006278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2833</th>\n",
       "      <td>close friend see you later</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499212</td>\n",
       "      <td>0.500788</td>\n",
       "      <td>0.001577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       title  \\\n",
       "10586                                                                 tırtıl   \n",
       "12028                                                                 angeri   \n",
       "11895                                            choooommmmppppppppppppppppp   \n",
       "10162                                                               lipstick   \n",
       "11508                                                       heheheheh 🤣🤣🤣🤣🤣🤣   \n",
       "10623                                                                  aboos   \n",
       "10494  i log onto a famili photo album and thi wa the first photo upload ...   \n",
       "10851                                                            duck v. cat   \n",
       "5882                             🔥 a smile black crest macaqu by mogen troll   \n",
       "2833                                              close friend see you later   \n",
       "\n",
       "       actual  predicted  P(r/AnimalsBeingBros)  P(r/AnimalsBeingJerks)  \\\n",
       "10586       1          0               0.503766                0.496234   \n",
       "12028       1          0               0.503766                0.496234   \n",
       "11895       1          0               0.503766                0.496234   \n",
       "10162       1          0               0.503766                0.496234   \n",
       "11508       1          0               0.503766                0.496234   \n",
       "10623       1          0               0.503766                0.496234   \n",
       "10494       1          0               0.503743                0.496257   \n",
       "10851       1          0               0.503720                0.496280   \n",
       "5882        0          1               0.496861                0.503139   \n",
       "2833        0          1               0.499212                0.500788   \n",
       "\n",
       "       Prob Diff  \n",
       "10586   0.007531  \n",
       "12028   0.007531  \n",
       "11895   0.007531  \n",
       "10162   0.007531  \n",
       "11508   0.007531  \n",
       "10623   0.007531  \n",
       "10494   0.007486  \n",
       "10851   0.007440  \n",
       "5882    0.006278  \n",
       "2833    0.001577  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.sort_values(by='Prob Diff', ascending = False).tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb04fbf-ca50-4673-b312-73abaababfa1",
   "metadata": {},
   "source": [
    "Again, some of these titles would be difficult even for a human to correctly classify. One worded titles like \"aboos,\" and \"lipstick\" would be very difficult to predict on. Unfortunatey, there is not a lot that my model can do to better predict those misclassifications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f57552f-672d-4d83-8c7f-363f0b396db8",
   "metadata": {},
   "source": [
    "# **3.5 Recommendations & Conclusions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e464a75-4701-435c-a27f-56fe8acb7e8e",
   "metadata": {},
   "source": [
    "### Recommendations to Improve Our Model\n",
    "\n",
    "The first recommendation to improve our model would be to collect more data. Since both of these subreddits are not text heavy, more posts should be collected. Second, another recommendation would be to include comments as a feature. At just an average of 6 words in each title, adding comments to our data would likely improve our model. My last recommendation would be to investigate more parameters.\n",
    "As wonderful as Pipelines and GridSearchCV are, using them in practice can be incredibly time consuming. More extensive searches with different parameters can be conducted to further optimize our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601b71a6-0e2e-41d9-9a62-4815be4a041c",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "With an average of just 6 words in each title to make predictions on, the model performed well. With many one worded, emoji, and slang titles, classifying these titles into their correct subreddits would be a task even humans would find difficult to do. The question remains answered; with a 45.7% improvement from our baseline model, yes, a model can outperform our baseline model when predicting which of two non text-heavy subreddits a post came from. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb098d-c73e-4bda-aced-fca3871e7367",
   "metadata": {},
   "source": [
    "# ***Want More?***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4fadc3-3e4d-4535-ba2c-f58af431ca5f",
   "metadata": {},
   "source": [
    "## [Presentation PDF](https://git.generalassemb.ly/ksylvia16/submissions_614/blob/master/Projects/project_3/presentation/Reddit%20API%20%26%20NLP%20Presentation.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
